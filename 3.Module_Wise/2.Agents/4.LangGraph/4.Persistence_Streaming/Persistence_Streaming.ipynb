{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5789bc3-b1ae-42c7-94a8-2ef4f89946fc",
   "metadata": {},
   "source": [
    "# Lesson 4: Persistence and Streaming\n",
    "\n",
    "\n",
    "Persistence - It lets you keep around the state of agent at a particular point in time. This can let you go back to that state and resume in that state in future interactions. This is really important for long running applications \n",
    "\n",
    "Streaming - You can emit list of signals of whats going on at that exact moment . So for long running applications , You know what exactly agent is doing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5762271-8736-4e94-9444-8c92bd0e8074",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da06a64f-a2d5-4a66-8090-9ada0930c684",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2e0e1a",
   "metadata": {},
   "source": [
    "We will just use in memory database for persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c033522-d2fc-41ac-8e3c-5e35872bf88d",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfe7162",
   "metadata": {
    "height": 30
   },
   "source": [
    "In order to add persistence , We have to add concept of checkpointer while creating agent .\n",
    "\n",
    "Checkpointer basically checkpoints the state after and between every node \n",
    "\n",
    "Persistence is nothing but adding memory in langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2ba84ec-c172-4de7-ac55-e3158a531b23",
   "metadata": {
    "height": 574
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer) ### pass checkpointer here\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10084a02-2928-4945-9f7c-ad3f5b33caf7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e670131",
   "metadata": {
    "height": 30
   },
   "source": [
    "This is used to keep track of different threads inside persistent checkpointes. Thread will allow us to have multiple conversations going on at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "714d1205-f8fc-4912-b148-2a45da99219c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edcb1c1",
   "metadata": {
    "height": 30
   },
   "source": [
    "Stream function return muttiple events . This event represents updates to that state over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83588e70-254f-4f83-a510-c8ae81e729b0",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_reRAy8NyyNkVb58Ku7regtwm', 'function': {'arguments': '{\"query\":\"current weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 151, 'total_tokens': 173}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_400f27fa1f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-92cb2394-9d26-450e-86eb-f1ea5e9e5116-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_reRAy8NyyNkVb58Ku7regtwm'}])]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_reRAy8NyyNkVb58Ku7regtwm'}\n",
      "Back to the model!\n",
      "[ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1721974836, \\'localtime\\': \\'2024-07-25 23:20\\'}, \\'current\\': {\\'last_updated_epoch\\': 1721974500, \\'last_updated\\': \\'2024-07-25 23:15\\', \\'temp_c\\': 13.7, \\'temp_f\\': 56.7, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Clear\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 8.1, \\'wind_kph\\': 13.0, \\'wind_degree\\': 247, \\'wind_dir\\': \\'WSW\\', \\'pressure_mb\\': 1016.0, \\'pressure_in\\': 30.0, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 81, \\'cloud\\': 0, \\'feelslike_c\\': 12.7, \\'feelslike_f\\': 54.9, \\'windchill_c\\': 12.7, \\'windchill_f\\': 54.9, \\'heatindex_c\\': 13.7, \\'heatindex_f\\': 56.7, \\'dewpoint_c\\': 10.3, \\'dewpoint_f\\': 50.6, \\'vis_km\\': 10.0, \\'vis_miles\\': 6.0, \\'uv\\': 1.0, \\'gust_mph\\': 12.8, \\'gust_kph\\': 20.7}}\"}, {\\'url\\': \\'https://www.ventusky.com/san-francisco\\', \\'content\\': \\'San Francisco ☀ Weather forecast for 10 days, information from meteorological stations, webcams, sunrise and sunset, wind and precipitation maps for this place ... America/Los_Angeles (UTC-7) / Current time: 16:04 2024/07/16 . Current Weather ; Forecast ; Sun and Moon ; 21 °C ... 26 km/h. 18 °C. 0 mm 0 %. W. 28 km/h. 15 °C. 0 mm 0 %. W. 22 ...\\'}]', name='tavily_search_results_json', tool_call_id='call_reRAy8NyyNkVb58Ku7regtwm')]\n",
      "[AIMessage(content='The current weather in San Francisco is clear with a temperature of 13.7°C (56.7°F). The wind is blowing from the west-southwest at 8.1 mph (13.0 kph). The humidity level is at 81%, and there is no precipitation. The visibility is 10 km, and the UV index is 1.', response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 722, 'total_tokens': 798}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_400f27fa1f', 'finish_reason': 'stop', 'logprobs': None}, id='run-c0e5c31f-e355-487b-9074-d57102bdf3f8-0')]\n"
     ]
    }
   ],
   "source": [
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbcaadf",
   "metadata": {
    "height": 30
   },
   "source": [
    "Now we are asking follow up question . We will check whether memory is maintained in langgrapgh or not with out checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_zmkdb9F6mZ9ANdN67wH2Hf6R', 'function': {'arguments': '{\"query\":\"current weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 810, 'total_tokens': 832}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_400f27fa1f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-13948219-1347-4206-8124-72984a7a0eca-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_zmkdb9F6mZ9ANdN67wH2Hf6R'}])]}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_zmkdb9F6mZ9ANdN67wH2Hf6R'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Los Angeles\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 34.05, \\'lon\\': -118.24, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1721974936, \\'localtime\\': \\'2024-07-25 23:22\\'}, \\'current\\': {\\'last_updated_epoch\\': 1721974500, \\'last_updated\\': \\'2024-07-25 23:15\\', \\'temp_c\\': 25.3, \\'temp_f\\': 77.5, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Clear\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 4.7, \\'wind_kph\\': 7.6, \\'wind_degree\\': 156, \\'wind_dir\\': \\'SSE\\', \\'pressure_mb\\': 1014.0, \\'pressure_in\\': 29.94, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 52, \\'cloud\\': 3, \\'feelslike_c\\': 26.2, \\'feelslike_f\\': 79.1, \\'windchill_c\\': 25.3, \\'windchill_f\\': 77.5, \\'heatindex_c\\': 26.2, \\'heatindex_f\\': 79.1, \\'dewpoint_c\\': 14.8, \\'dewpoint_f\\': 58.6, \\'vis_km\\': 10.0, \\'vis_miles\\': 6.0, \\'uv\\': 1.0, \\'gust_mph\\': 6.3, \\'gust_kph\\': 10.1}}\"}, {\\'url\\': \\'https://www.weather.gov/lox/\\', \\'content\\': \\'Last Map Update: Thu, Jul 25, 2024 at 12:04:16 am PDT Watches, Warnings & Advisories. Zoom Out. Excessive Heat Warning. Heat Advisory ... (Selected product opens in current window) Hazards. Observations. Marine Weather. Fire Weather ... National Weather Service Los Angeles, CA 520 North Elevar Street Oxnard, CA 93030 805-988-6610 ...\\'}]', name='tavily_search_results_json', tool_call_id='call_zmkdb9F6mZ9ANdN67wH2Hf6R')]}\n",
      "{'messages': [AIMessage(content='The current weather in Los Angeles is clear with a temperature of 25.3°C (77.5°F). The wind is coming from the south-southeast at 4.7 mph (7.6 kph). The humidity level is at 52%, and there is no precipitation. The visibility is 10 km, and the UV index is 1.', response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 1354, 'total_tokens': 1430}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_18cc0f1fa0', 'finish_reason': 'stop', 'logprobs': None}, id='run-f5c3def7-a6f9-48ba-b115-d8999c7d32d3-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What about in la?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='Los Angeles is currently warmer than San Francisco. The temperature in Los Angeles is 25.3°C (77.5°F), whereas in San Francisco, it is 13.7°C (56.7°F).', response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 1442, 'total_tokens': 1487}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_18cc0f1fa0', 'finish_reason': 'stop', 'logprobs': None}, id='run-fbd2c479-98f1-45b0-abab-f6eace1aa7d7-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bddfc3",
   "metadata": {
    "height": 30
   },
   "source": [
    "When you change threadid , memory is lost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='Could you please clarify what you are comparing for warmth? Are you referring to:\\n\\n1. Clothing materials (e.g., wool vs. cotton)?\\n2. Specific geographical locations (e.g., New York vs. Los Angeles)?\\n3. Types of insulation (e.g., fiberglass vs. foam)?\\n4. Or something else entirely?\\n\\nThis will help me provide a more accurate answer.', response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 149, 'total_tokens': 226}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_400f27fa1f', 'finish_reason': 'stop', 'logprobs': None}, id='run-03347a5d-5bdf-463c-b5cb-b6ac6a31af90-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace59a36-3941-459e-b9d1-ac5a4a1ed3ae",
   "metadata": {},
   "source": [
    "## Streaming tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n",
    "\n",
    "memory = AsyncSqliteSaver.from_conn_string(\":memory:\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee0fe1c7-77e2-499c-a2f9-1f739bb6ddf0",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_pmcRuSV8w0D7gNTLA1mku6zY'}\n",
      "Back to the model!\n",
      "The| current| weather| in| San| Francisco| is| clear| with| a| temperature| of| |13|.|7|°C| (|56|.|7|°F|).| The| wind| is| blowing| from| the| west|-s|outh|west| at| |8|.|1| mph| (|13|.|0| k|ph|),| and| the| humidity| is| at| |81|%.| The| visibility| is| |10| km| (|6| miles|),| and| the| UV| index| is| |1|.|"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "async for event in abot.graph.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\": ## specific type of event for streaming tokens\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f303b1-a4d0-408c-8cc0-515ff980717f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
